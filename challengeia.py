# -*- coding: utf-8 -*-
"""ChallengeIa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NRd2dP8h0Dp8o62tn8jiAK-zHqh06SoQ
"""

pip install streamlit

from google.colab import drive
drive.mount('/content/drive')

import streamlit as st
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from flask import Flask, request, jsonify
from tensorflow.keras.models import load_model
import numpy as np
from tensorflow.keras.preprocessing import image
import os

# Configurações
input_shape = (224, 224, 3)  # Tamanho da imagem
batch_size = 32
epochs = 10

# Criando o modelo
model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(4, activation='softmax'))  # 4 classes

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Pré-processamento das imagens
train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
   '/content/drive/MyDrive/PastasImagens',
   target_size=(224, 224),
   batch_size=batch_size,
   class_mode='categorical',
   subset='training'
)

validation_generator = train_datagen.flow_from_directory(
   '/content/drive/MyDrive/PastasImagens',
   target_size=(224, 224),
   batch_size=batch_size,
   class_mode='categorical',
   subset='validation'
)

# Treinando o modelo
model.fit(train_generator, epochs=epochs, validation_data=validation_generator)

# Salvando o modelo
model.save('modelo_chatbot.keras')

# Carregando o modelo
loaded_model = load_model('modelo_chatbot.keras')

#Define the prediction function
def predict(image):
    img = img_to_array(load_img(image, target_size=(224, 224))) / 255.0
    img = np.expand_dims(img, axis=0)
    result = loaded_model.predict(img)
    class_index = np.argmax(result)
    classes = {0: 'caminhão porte grande', 1: 'caminhão porte médio', 2: 'caminhão porte pequeno', 3: 'fotos estradas'}
    prediction = classes[class_index]
    return prediction

#Create the Streamlit app
st.title('Classificação de Imagens de Caminhões')

#Upload the image
uploaded_file = st.file_uploader('Upload a truck image')

#Make the prediction
if uploaded_file is not None:
    prediction = predict(uploaded_file)
    st.write(f'Predicted class: {prediction}')

!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py